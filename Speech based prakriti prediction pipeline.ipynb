{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDOyydyNNK2W"
      },
      "source": [
        "# A Computational Approach to Ayurvedic Prakriti Assessment Through Speech Signal Analysis\n",
        "This repository contains the complete workflow for a research project focused on predicting Ayurvedic *Prakriti* types (Vata, Pitta, Kapha) using machine learning models trained on speech-based acoustic features.  \n",
        "The dataset was collected from real participants through controlled speech recordings, ensuring natural variability and authenticity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoW8YRk2NK2X"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "This section initializes the core Python environment used throughout the project.  \n",
        "We import essential libraries for numerical computation and data handling, and list the available input files in the working directory.  \n",
        "This setup ensures reproducibility and provides visibility into the dataset structure, especially when running the notebook on cloud platforms such as Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "xTZHc566POPX",
        "outputId": "de291199-02a8-4dca-d473-9afb522412a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-41d40b6f-aa39-4b4a-a760-dab8f58e519d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-41d40b6f-aa39-4b4a-a760-dab8f58e519d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Dataset.csv to Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "MXKFQvk5NK2Y",
        "outputId": "bc37bdee-d5d4-4350-af7a-09b85ad20f44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    AudioFileName     1      2     3     4  \\\n",
              "0          0202fe23bcs152 - male_egemaps_features  30.3  0.181  28.3  29.5   \n",
              "1  0202fe23bcs152 - male_gain0.9_egemaps_features  30.3  0.176  28.3  29.5   \n",
              "2  0202fe23bcs152 - male_gain1.0_egemaps_features  30.3  0.181  28.3  29.5   \n",
              "3  0202fe23bcs152 - male_gain1.1_egemaps_features  30.4  0.185  28.3  29.5   \n",
              "4  0202fe23bcs152 - male_gain1.2_egemaps_features  30.5  0.191  28.3  29.5   \n",
              "\n",
              "      5     6      7      8      9  ...           SRN    Student_ID  \\\n",
              "0  31.6  3.25  374.0  803.0  226.0  ...  02fe23bcs152  02fe23bcs152   \n",
              "1  31.6  3.25  375.0  803.0  235.0  ...  02fe23bcs152  02fe23bcs152   \n",
              "2  31.6  3.25  374.0  803.0  226.0  ...  02fe23bcs152  02fe23bcs152   \n",
              "3  31.6  3.28  530.0  963.0  258.0  ...  02fe23bcs152  02fe23bcs152   \n",
              "4  31.6  3.34  528.0  958.0  343.0  ...  02fe23bcs152  02fe23bcs152   \n",
              "\n",
              "            Name  Vata_Score  Pitta_Score  Kapha_Score  Vata_Percentage  \\\n",
              "0  Rahul Jadhav            3           10            3            18.75   \n",
              "1  Rahul Jadhav            3           10            3            18.75   \n",
              "2  Rahul Jadhav            3           10            3            18.75   \n",
              "3  Rahul Jadhav            3           10            3            18.75   \n",
              "4  Rahul Jadhav            3           10            3            18.75   \n",
              "\n",
              "   Pitta_Percentage  Kapha_Percentage  Dominant_Prakriti  \n",
              "0              62.5             18.75              Pitta  \n",
              "1              62.5             18.75              Pitta  \n",
              "2              62.5             18.75              Pitta  \n",
              "3              62.5             18.75              Pitta  \n",
              "4              62.5             18.75              Pitta  \n",
              "\n",
              "[5 rows x 105 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a999c71-6a0d-4ed7-98f4-faccd1dfa6f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AudioFileName</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>SRN</th>\n",
              "      <th>Student_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Vata_Score</th>\n",
              "      <th>Pitta_Score</th>\n",
              "      <th>Kapha_Score</th>\n",
              "      <th>Vata_Percentage</th>\n",
              "      <th>Pitta_Percentage</th>\n",
              "      <th>Kapha_Percentage</th>\n",
              "      <th>Dominant_Prakriti</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0202fe23bcs152 - male_egemaps_features</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0.181</td>\n",
              "      <td>28.3</td>\n",
              "      <td>29.5</td>\n",
              "      <td>31.6</td>\n",
              "      <td>3.25</td>\n",
              "      <td>374.0</td>\n",
              "      <td>803.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>...</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>Rahul Jadhav</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>18.75</td>\n",
              "      <td>62.5</td>\n",
              "      <td>18.75</td>\n",
              "      <td>Pitta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0202fe23bcs152 - male_gain0.9_egemaps_features</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0.176</td>\n",
              "      <td>28.3</td>\n",
              "      <td>29.5</td>\n",
              "      <td>31.6</td>\n",
              "      <td>3.25</td>\n",
              "      <td>375.0</td>\n",
              "      <td>803.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>...</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>Rahul Jadhav</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>18.75</td>\n",
              "      <td>62.5</td>\n",
              "      <td>18.75</td>\n",
              "      <td>Pitta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0202fe23bcs152 - male_gain1.0_egemaps_features</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0.181</td>\n",
              "      <td>28.3</td>\n",
              "      <td>29.5</td>\n",
              "      <td>31.6</td>\n",
              "      <td>3.25</td>\n",
              "      <td>374.0</td>\n",
              "      <td>803.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>...</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>Rahul Jadhav</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>18.75</td>\n",
              "      <td>62.5</td>\n",
              "      <td>18.75</td>\n",
              "      <td>Pitta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0202fe23bcs152 - male_gain1.1_egemaps_features</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.185</td>\n",
              "      <td>28.3</td>\n",
              "      <td>29.5</td>\n",
              "      <td>31.6</td>\n",
              "      <td>3.28</td>\n",
              "      <td>530.0</td>\n",
              "      <td>963.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>...</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>Rahul Jadhav</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>18.75</td>\n",
              "      <td>62.5</td>\n",
              "      <td>18.75</td>\n",
              "      <td>Pitta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0202fe23bcs152 - male_gain1.2_egemaps_features</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.191</td>\n",
              "      <td>28.3</td>\n",
              "      <td>29.5</td>\n",
              "      <td>31.6</td>\n",
              "      <td>3.34</td>\n",
              "      <td>528.0</td>\n",
              "      <td>958.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>...</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>02fe23bcs152</td>\n",
              "      <td>Rahul Jadhav</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>18.75</td>\n",
              "      <td>62.5</td>\n",
              "      <td>18.75</td>\n",
              "      <td>Pitta</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 105 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a999c71-6a0d-4ed7-98f4-faccd1dfa6f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a999c71-6a0d-4ed7-98f4-faccd1dfa6f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a999c71-6a0d-4ed7-98f4-faccd1dfa6f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-569096ee-2e85-41c1-a585-3ca975e65d15\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-569096ee-2e85-41c1-a585-3ca975e65d15')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-569096ee-2e85-41c1-a585-3ca975e65d15 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "base_path = os.getcwd()\n",
        "df = pd.read_csv(\"Dataset.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IH1Of4NNK2Y"
      },
      "source": [
        "## 2. Data Loading, Feature Aggregation, and Random Forest Classification\n",
        "\n",
        "This section handles the complete workflow for preparing the dataset and training a student-level Prakriti prediction model using a Random Forest classifier.\n",
        "\n",
        "### **2.1 Load Dataset**\n",
        "The final speech–feature dataset is loaded from the input directory. Non-numeric identifiers such as `SRN`, `Student_ID`, and `Name` are excluded when constructing the feature set.\n",
        "\n",
        "### **2.2 Aggregate Numeric Features**\n",
        "Since each participant contributes multiple speech frames, all numeric acoustic features are aggregated per student using:\n",
        "- Mean  \n",
        "- Standard deviation  \n",
        "- Minimum  \n",
        "- Maximum  \n",
        "\n",
        "This produces a single feature vector per student and prevents leakage across rows belonging to the same individual.\n",
        "\n",
        "### **2.3 Train–Test Split (Student-Level)**\n",
        "A strict student-level split is performed using unique `SRN` identifiers, ensuring no overlap between training and testing participants.\n",
        "\n",
        "### **2.4 Model Training**\n",
        "A Random Forest classifier is trained using balanced class weights and optimized hyperparameters. The model learns to predict each student's Dominant Prakriti type from their aggregated speech features.\n",
        "\n",
        "### **2.5 Evaluation Metrics**\n",
        "The trained model is evaluated using:\n",
        "- Accuracy  \n",
        "- Precision  \n",
        "- Recall  \n",
        "- F1-score  \n",
        "- Confusion matrix  \n",
        "- Classification report  \n",
        "- Feature importance ranking  \n",
        "\n",
        "### **2.6 Cross-Validation**\n",
        "A 5-fold **GroupKFold** cross-validation (grouped by `SRN`) provides a stringent and unbiased estimate of the model’s generalization performance.\n",
        "\n",
        "This section forms the core experimental pipeline for Prakriti prediction from real-world speech data collected from participants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3D8EygC3NK2Z",
        "outputId": "8f729c11-5018-4010-e8ed-c19cff36b1d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "RANDOM FOREST CLASSIFIER - STUDENT-LEVEL SPLIT\n",
            "================================================================================\n",
            "Total students: 365\n",
            "Training students: 292\n",
            "Testing students: 73\n",
            "Training samples: 292\n",
            "Testing samples: 73\n",
            "\n",
            "Dominant Prakriti distribution (entire dataset):\n",
            "Dominant_Prakriti\n",
            "Pitta    275\n",
            "Kapha     56\n",
            "Vata      34\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Model training complete\n",
            "\n",
            "================================================================================\n",
            "PERFORMANCE METRICS\n",
            "================================================================================\n",
            "Training Accuracy: 99.66%\n",
            "Testing Accuracy: 95.89%\n",
            "Precision: 96.51%\n",
            "Recall: 95.89%\n",
            "F1-Score: 96.00%\n",
            "\n",
            "Confusion Matrix:\n",
            "[[12  0  0]\n",
            " [ 2 53  1]\n",
            " [ 0  0  5]]\n",
            "\n",
            "================================================================================\n",
            "CLASSIFICATION REPORT\n",
            "================================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Kapha       0.86      1.00      0.92        12\n",
            "       Pitta       1.00      0.95      0.97        56\n",
            "        Vata       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.96        73\n",
            "   macro avg       0.90      0.98      0.93        73\n",
            "weighted avg       0.97      0.96      0.96        73\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FEATURE IMPORTANCE\n",
            "================================================================================\n",
            "               Feature   Importance\n",
            "       Vata_Score_mean 5.891316e-02\n",
            "      Pitta_Score_mean 5.141915e-02\n",
            "   Vata_Percentage_max 5.073857e-02\n",
            "   Vata_Percentage_min 4.576932e-02\n",
            "       Kapha_Score_min 4.573331e-02\n",
            "        Vata_Score_min 4.532817e-02\n",
            "  Pitta_Percentage_max 4.230430e-02\n",
            "  Pitta_Percentage_min 4.196723e-02\n",
            "       Pitta_Score_min 4.123771e-02\n",
            "        Vata_Score_max 4.023280e-02\n",
            " Kapha_Percentage_mean 3.852856e-02\n",
            "  Vata_Percentage_mean 3.842712e-02\n",
            "  Kapha_Percentage_max 3.722493e-02\n",
            "  Kapha_Percentage_min 3.690614e-02\n",
            "       Kapha_Score_max 3.588106e-02\n",
            "      Kapha_Score_mean 3.373093e-02\n",
            "       Pitta_Score_max 3.358381e-02\n",
            " Pitta_Percentage_mean 3.040184e-02\n",
            "                71_std 3.814763e-03\n",
            "                29_std 3.340930e-03\n",
            "               62_mean 2.891319e-03\n",
            "                43_max 2.348692e-03\n",
            "                27_std 2.308510e-03\n",
            "                73_std 2.291535e-03\n",
            "                43_min 2.275732e-03\n",
            "                28_std 2.267431e-03\n",
            "                31_std 2.248411e-03\n",
            "                68_std 2.204712e-03\n",
            "                19_max 2.162639e-03\n",
            "               37_mean 2.052721e-03\n",
            "                38_std 2.029045e-03\n",
            "               31_mean 1.918484e-03\n",
            "                2_mean 1.864407e-03\n",
            "                25_std 1.827410e-03\n",
            "                37_min 1.822457e-03\n",
            "                26_max 1.819755e-03\n",
            "                39_max 1.795997e-03\n",
            "                37_max 1.774663e-03\n",
            "                59_std 1.732563e-03\n",
            "                49_min 1.723399e-03\n",
            "                19_std 1.687680e-03\n",
            " intensity_std_dev_min 1.687622e-03\n",
            "                38_max 1.643534e-03\n",
            "                54_std 1.592560e-03\n",
            "                23_max 1.523975e-03\n",
            "                24_std 1.517106e-03\n",
            "                66_std 1.514276e-03\n",
            "                70_max 1.504778e-03\n",
            "               53_mean 1.489835e-03\n",
            "               43_mean 1.485618e-03\n",
            "                30_min 1.467637e-03\n",
            "                60_std 1.446701e-03\n",
            "                85_std 1.433294e-03\n",
            "                14_min 1.400707e-03\n",
            "                17_min 1.399966e-03\n",
            "                75_std 1.391104e-03\n",
            "                55_std 1.385423e-03\n",
            "                81_std 1.328742e-03\n",
            "               26_mean 1.320169e-03\n",
            "                36_std 1.319022e-03\n",
            "               73_mean 1.286464e-03\n",
            "                 8_std 1.284217e-03\n",
            "                52_std 1.282786e-03\n",
            "                19_min 1.281151e-03\n",
            "                56_std 1.274175e-03\n",
            "                23_std 1.271269e-03\n",
            "               41_mean 1.269427e-03\n",
            "                16_std 1.262437e-03\n",
            "                 9_min 1.244378e-03\n",
            "    energy_std_dev_min 1.243394e-03\n",
            "                 7_std 1.239969e-03\n",
            "                77_std 1.235722e-03\n",
            "               72_mean 1.233365e-03\n",
            "                30_max 1.223820e-03\n",
            "               47_mean 1.187309e-03\n",
            "                45_std 1.131797e-03\n",
            "                39_std 1.125508e-03\n",
            "               19_mean 1.112469e-03\n",
            "                76_std 1.104853e-03\n",
            "               25_mean 1.093784e-03\n",
            "                65_min 1.090858e-03\n",
            "                5_mean 1.080438e-03\n",
            "    energy_std_dev_max 1.077922e-03\n",
            "                39_min 1.075959e-03\n",
            "                83_min 1.061625e-03\n",
            "                 3_std 1.046236e-03\n",
            "                58_max 1.043447e-03\n",
            "               20_mean 1.034289e-03\n",
            "                72_min 1.033127e-03\n",
            "                31_max 1.019229e-03\n",
            "                34_std 1.017030e-03\n",
            "                41_min 1.015621e-03\n",
            "               68_mean 1.012821e-03\n",
            "                82_max 1.005214e-03\n",
            "                72_std 9.956942e-04\n",
            "       zcr_std_dev_std 9.900649e-04\n",
            "                72_max 9.727853e-04\n",
            "                58_min 9.671011e-04\n",
            "                58_std 9.630184e-04\n",
            "                48_max 9.617048e-04\n",
            "                47_min 9.615839e-04\n",
            "               28_mean 9.583828e-04\n",
            "                20_max 9.554289e-04\n",
            "                13_min 9.520791e-04\n",
            "                4_mean 9.501738e-04\n",
            "               65_mean 9.449957e-04\n",
            "                79_min 9.415653e-04\n",
            "                25_min 9.397117e-04\n",
            "                36_min 9.325583e-04\n",
            "               10_mean 9.309311e-04\n",
            "               61_mean 9.289339e-04\n",
            "       energy_mean_min 9.281024e-04\n",
            "                 2_min 9.204167e-04\n",
            "                78_min 9.107798e-04\n",
            "                78_std 9.074085e-04\n",
            "                33_std 9.036681e-04\n",
            "                69_std 9.033368e-04\n",
            "                51_std 8.967254e-04\n",
            "                71_min 8.782250e-04\n",
            "                9_mean 8.651091e-04\n",
            "                13_max 8.607781e-04\n",
            "               71_mean 8.527594e-04\n",
            "                87_max 8.499622e-04\n",
            "                26_min 8.491433e-04\n",
            "                62_std 8.378135e-04\n",
            "                76_min 8.303782e-04\n",
            "                84_min 8.201202e-04\n",
            "                32_std 8.195534e-04\n",
            "                76_max 8.164941e-04\n",
            "                15_min 8.102490e-04\n",
            "                38_min 8.080086e-04\n",
            "                55_max 7.893110e-04\n",
            "                33_min 7.823963e-04\n",
            "                10_max 7.810287e-04\n",
            "                29_max 7.775012e-04\n",
            "                14_max 7.760732e-04\n",
            "                70_std 7.760032e-04\n",
            "               59_mean 7.752691e-04\n",
            "       energy_mean_std 7.732394e-04\n",
            "                49_std 7.696948e-04\n",
            "                32_min 7.672242e-04\n",
            "      energy_mean_mean 7.652451e-04\n",
            "                33_max 7.647126e-04\n",
            "                35_std 7.477476e-04\n",
            "                28_max 7.453747e-04\n",
            "                27_min 7.419812e-04\n",
            "                40_max 7.417318e-04\n",
            "                25_max 7.374263e-04\n",
            "                10_min 7.334351e-04\n",
            "                1_mean 7.267478e-04\n",
            "                31_min 7.235338e-04\n",
            "                44_min 7.194852e-04\n",
            "                61_max 7.181990e-04\n",
            "                15_std 7.039421e-04\n",
            "                63_std 6.883353e-04\n",
            "               77_mean 6.853015e-04\n",
            " intensity_std_dev_std 6.835529e-04\n",
            "                65_std 6.820559e-04\n",
            "                24_max 6.799350e-04\n",
            "               60_mean 6.799072e-04\n",
            "               80_mean 6.794812e-04\n",
            "                62_max 6.765253e-04\n",
            "                42_min 6.755869e-04\n",
            "                22_min 6.702202e-04\n",
            "                23_min 6.689914e-04\n",
            "                60_max 6.661167e-04\n",
            "               40_mean 6.647188e-04\n",
            "                20_std 6.623332e-04\n",
            "                57_std 6.613158e-04\n",
            "                35_min 6.581385e-04\n",
            "                63_max 6.566222e-04\n",
            "                61_min 6.468599e-04\n",
            "                86_std 6.451074e-04\n",
            "                57_min 6.325719e-04\n",
            "                77_max 6.299905e-04\n",
            "                 9_max 6.249621e-04\n",
            "                73_max 6.216661e-04\n",
            "                79_std 6.209118e-04\n",
            "                82_std 6.180258e-04\n",
            "                85_max 6.175943e-04\n",
            "                 4_max 6.076898e-04\n",
            "                56_min 6.019838e-04\n",
            "               84_mean 5.965935e-04\n",
            "                22_max 5.932654e-04\n",
            "                 6_min 5.873759e-04\n",
            "                37_std 5.864632e-04\n",
            "                71_max 5.827651e-04\n",
            "               18_mean 5.786343e-04\n",
            "                82_min 5.703634e-04\n",
            "                 9_std 5.697471e-04\n",
            "                45_max 5.691706e-04\n",
            "               67_mean 5.651251e-04\n",
            "          zcr_mean_min 5.634557e-04\n",
            "               27_mean 5.588622e-04\n",
            "                20_min 5.560669e-04\n",
            "                84_max 5.454707e-04\n",
            "                59_min 5.442141e-04\n",
            "               35_mean 5.429786e-04\n",
            "                81_min 5.392047e-04\n",
            "               48_mean 5.381038e-04\n",
            "               63_mean 5.349298e-04\n",
            "               70_mean 5.343470e-04\n",
            "               23_mean 5.202366e-04\n",
            "                14_std 5.178238e-04\n",
            "                80_std 5.170210e-04\n",
            "                68_min 5.160983e-04\n",
            "                78_max 5.150220e-04\n",
            "                 1_min 5.139436e-04\n",
            "               78_mean 5.085193e-04\n",
            "               44_mean 5.081481e-04\n",
            "                52_max 5.077722e-04\n",
            "                47_max 4.970163e-04\n",
            "                55_min 4.960494e-04\n",
            "                46_std 4.919248e-04\n",
            "                80_max 4.908714e-04\n",
            "                44_max 4.899508e-04\n",
            "               33_mean 4.860075e-04\n",
            "                 6_max 4.849419e-04\n",
            "               54_mean 4.793560e-04\n",
            "                 7_min 4.775295e-04\n",
            "                84_std 4.774254e-04\n",
            "                59_max 4.770456e-04\n",
            "                51_min 4.769652e-04\n",
            "                 8_max 4.703315e-04\n",
            "                74_std 4.702746e-04\n",
            "                32_max 4.697428e-04\n",
            "                 3_max 4.688733e-04\n",
            "                81_max 4.666995e-04\n",
            "                16_max 4.650924e-04\n",
            "                15_max 4.650448e-04\n",
            "                 7_max 4.585561e-04\n",
            "               38_mean 4.543951e-04\n",
            "                88_min 4.526933e-04\n",
            "                24_min 4.522031e-04\n",
            "               74_mean 4.505574e-04\n",
            "                50_std 4.488870e-04\n",
            "                62_min 4.483860e-04\n",
            "                26_std 4.455767e-04\n",
            "                53_min 4.406770e-04\n",
            "               32_mean 4.360180e-04\n",
            "               49_mean 4.348171e-04\n",
            "                79_max 4.334676e-04\n",
            "                61_std 4.332460e-04\n",
            "                10_std 4.332264e-04\n",
            "                83_max 4.318675e-04\n",
            "                66_max 4.237289e-04\n",
            "                44_std 4.229961e-04\n",
            "                27_max 4.194932e-04\n",
            "                40_std 4.151520e-04\n",
            "       zcr_std_dev_max 4.134495e-04\n",
            "                34_min 4.111944e-04\n",
            "                42_max 4.110504e-04\n",
            "                68_max 4.085977e-04\n",
            "                22_std 4.073421e-04\n",
            "                36_max 4.070957e-04\n",
            "                41_max 4.068200e-04\n",
            "                17_std 4.017435e-04\n",
            "                 1_max 4.006372e-04\n",
            "               42_mean 3.976792e-04\n",
            "    intensity_mean_min 3.943551e-04\n",
            "                12_max 3.920562e-04\n",
            "               56_mean 3.900224e-04\n",
            "               39_mean 3.885300e-04\n",
            "               46_mean 3.771950e-04\n",
            "                3_mean 3.742838e-04\n",
            "                83_std 3.698757e-04\n",
            "                 2_std 3.690243e-04\n",
            "      zcr_std_dev_mean 3.678576e-04\n",
            "                18_min 3.675957e-04\n",
            "                67_max 3.666047e-04\n",
            "               64_mean 3.628109e-04\n",
            "         zcr_mean_mean 3.622757e-04\n",
            "               83_mean 3.591658e-04\n",
            "                88_max 3.574025e-04\n",
            "                64_min 3.563646e-04\n",
            "               45_mean 3.562817e-04\n",
            "                28_min 3.464997e-04\n",
            "               24_mean 3.452069e-04\n",
            "                 8_min 3.449345e-04\n",
            "                65_max 3.403081e-04\n",
            "               22_mean 3.398592e-04\n",
            "               52_mean 3.393102e-04\n",
            "intensity_std_dev_mean 3.336130e-04\n",
            "                67_min 3.331752e-04\n",
            " intensity_std_dev_max 3.327492e-04\n",
            "               88_mean 3.312229e-04\n",
            "                74_max 3.267267e-04\n",
            "               75_mean 3.224760e-04\n",
            "                30_std 3.207422e-04\n",
            "               85_mean 3.196136e-04\n",
            "                48_min 3.165205e-04\n",
            "                88_std 3.162244e-04\n",
            "               36_mean 3.147597e-04\n",
            "                50_min 3.099190e-04\n",
            "               14_mean 3.078936e-04\n",
            "                 1_std 3.072757e-04\n",
            "    energy_std_dev_std 3.020570e-04\n",
            "                21_min 3.016119e-04\n",
            "               79_mean 3.005717e-04\n",
            "    intensity_mean_max 2.914245e-04\n",
            "               11_mean 2.914200e-04\n",
            "                75_min 2.911561e-04\n",
            "                42_std 2.909856e-04\n",
            "               13_mean 2.909600e-04\n",
            "       zcr_std_dev_min 2.889091e-04\n",
            "                6_mean 2.841471e-04\n",
            "                77_min 2.810386e-04\n",
            "                45_min 2.740894e-04\n",
            "               57_mean 2.717923e-04\n",
            "                53_std 2.645540e-04\n",
            "                29_min 2.604769e-04\n",
            "               15_mean 2.567255e-04\n",
            "               81_mean 2.562756e-04\n",
            "                64_max 2.492396e-04\n",
            "                54_max 2.403078e-04\n",
            "                51_max 2.390447e-04\n",
            "               58_mean 2.267043e-04\n",
            "               76_mean 2.224713e-04\n",
            "               55_mean 2.217924e-04\n",
            "                48_std 2.169151e-04\n",
            "               66_mean 2.113317e-04\n",
            "                86_max 2.082215e-04\n",
            "                34_max 2.072922e-04\n",
            "       energy_mean_max 2.068383e-04\n",
            "   energy_std_dev_mean 2.025878e-04\n",
            "                75_max 2.004609e-04\n",
            "                 2_max 1.949229e-04\n",
            "                57_max 1.926733e-04\n",
            "                12_min 1.920042e-04\n",
            "                21_max 1.869949e-04\n",
            "                80_min 1.848322e-04\n",
            "                46_max 1.827825e-04\n",
            "                70_min 1.827761e-04\n",
            "                17_max 1.824282e-04\n",
            "                11_max 1.812340e-04\n",
            "                56_max 1.792392e-04\n",
            "          zcr_mean_max 1.738811e-04\n",
            "                 6_std 1.711674e-04\n",
            "               30_mean 1.691221e-04\n",
            "                50_max 1.680775e-04\n",
            "                16_min 1.631287e-04\n",
            "                49_max 1.613263e-04\n",
            "                63_min 1.533852e-04\n",
            "                86_min 1.533077e-04\n",
            "                73_min 1.428897e-04\n",
            "                41_std 1.419045e-04\n",
            "               29_mean 1.400741e-04\n",
            "                87_std 1.379046e-04\n",
            "                64_std 1.378519e-04\n",
            "                43_std 1.358451e-04\n",
            "                66_min 1.348903e-04\n",
            "               50_mean 1.341098e-04\n",
            "               12_mean 1.326175e-04\n",
            "          zcr_mean_std 1.314191e-04\n",
            "                 4_std 1.312896e-04\n",
            "                 3_min 1.296696e-04\n",
            "               87_mean 1.254943e-04\n",
            "                60_min 1.235924e-04\n",
            "               69_mean 1.198740e-04\n",
            "                11_min 1.167798e-04\n",
            "                13_std 1.159440e-04\n",
            "    intensity_mean_std 1.149669e-04\n",
            "                18_max 1.043719e-04\n",
            "                46_min 1.026918e-04\n",
            "                85_min 1.026234e-04\n",
            "                7_mean 1.018745e-04\n",
            "                69_max 1.015405e-04\n",
            "               21_mean 9.973785e-05\n",
            "                8_mean 9.853454e-05\n",
            "                12_std 9.817430e-05\n",
            "                 5_max 9.688434e-05\n",
            "                 5_min 9.603238e-05\n",
            "               86_mean 9.364428e-05\n",
            "                18_std 9.007486e-05\n",
            "                87_min 8.156215e-05\n",
            "                74_min 8.004645e-05\n",
            "                35_max 7.805233e-05\n",
            "                69_min 7.770865e-05\n",
            "                 5_std 6.905780e-05\n",
            "   intensity_mean_mean 6.760850e-05\n",
            "               51_mean 5.542754e-05\n",
            "               34_mean 5.411591e-05\n",
            "                67_std 5.296045e-05\n",
            "                 4_min 4.760028e-05\n",
            "                47_std 4.539220e-05\n",
            "               82_mean 4.302398e-05\n",
            "                11_std 3.828443e-05\n",
            "                40_min 3.409356e-05\n",
            "                54_min 1.312376e-05\n",
            "               17_mean 1.116078e-05\n",
            "                52_min 2.531377e-06\n",
            "               16_mean 4.579271e-17\n",
            "  Kapha_Percentage_std 0.000000e+00\n",
            "       Kapha_Score_std 0.000000e+00\n",
            "   Vata_Percentage_std 0.000000e+00\n",
            "  Pitta_Percentage_std 0.000000e+00\n",
            "                21_std 0.000000e+00\n",
            "                53_max 0.000000e+00\n",
            "        Vata_Score_std 0.000000e+00\n",
            "       Pitta_Score_std 0.000000e+00\n",
            "\n",
            "5-Fold GroupKFold CV Accuracy (student-level): 94.79% (+/- 4.37%)\n",
            "MODEL EVALUATION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GroupKFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load final dataset\n",
        "dataset_path = \"Dataset.csv\"\n",
        "df = pd.read_csv(dataset_path, encoding='utf-8-sig')\n",
        "\n",
        "# Identify numeric features for aggregation\n",
        "# Exclude identifiers and target\n",
        "exclude_cols = ['SRN', 'Student_ID', 'Name', 'Dominant_Prakriti']\n",
        "numeric_features = df.select_dtypes(include='number').columns.tolist()\n",
        "feature_cols = [col for col in numeric_features if col not in exclude_cols]\n",
        "\n",
        "# Aggregate numeric features per student\n",
        "df_agg = df.groupby('SRN')[feature_cols].agg(['mean','std','min','max'])\n",
        "df_agg.columns = ['_'.join(col).strip() for col in df_agg.columns.values]\n",
        "df_agg = df_agg.reset_index()\n",
        "\n",
        "# Merge Dominant_Prakriti labels\n",
        "labels = df[['SRN','Dominant_Prakriti']].drop_duplicates()\n",
        "df_final = pd.merge(df_agg, labels, on='SRN', how='left')\n",
        "\n",
        "# Features and target\n",
        "X = df_final.drop(columns=['SRN','Dominant_Prakriti'])\n",
        "y = df_final['Dominant_Prakriti']\n",
        "groups = df_final['SRN']\n",
        "\n",
        "# Student-level train-test split\n",
        "unique_srns = df_final['SRN'].unique()\n",
        "train_srns, test_srns = train_test_split(unique_srns, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X[df_final['SRN'].isin(train_srns)]\n",
        "y_train = y[df_final['SRN'].isin(train_srns)]\n",
        "X_test = X[df_final['SRN'].isin(test_srns)]\n",
        "y_test = y[df_final['SRN'].isin(test_srns)]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"RANDOM FOREST CLASSIFIER - STUDENT-LEVEL SPLIT\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total students: {len(unique_srns)}\")\n",
        "print(f\"Training students: {len(train_srns)}\")\n",
        "print(f\"Testing students: {len(test_srns)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(\"\\nDominant Prakriti distribution (entire dataset):\")\n",
        "print(df_final['Dominant_Prakriti'].value_counts())\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"\\nModel training complete\")\n",
        "\n",
        "# Predictions and evaluation\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "train_acc = rf.score(X_train, y_train)\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE METRICS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Training Accuracy: {train_acc*100:.2f}%\")\n",
        "print(f\"Testing Accuracy: {test_acc*100:.2f}%\")\n",
        "print(f\"Precision: {precision*100:.2f}%\")\n",
        "print(f\"Recall: {recall*100:.2f}%\")\n",
        "print(f\"F1-Score: {f1*100:.2f}%\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Feature importance\n",
        "fi_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FEATURE IMPORTANCE\")\n",
        "print(\"=\"*80)\n",
        "print(fi_df.to_string(index=False))\n",
        "\n",
        "# 5-Fold GroupKFold Cross-validation\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "cv_scores = cross_val_score(rf, X, y, groups=groups, cv=gkf)\n",
        "print(f\"\\n5-Fold GroupKFold CV Accuracy (student-level): {cv_scores.mean()*100:.2f}% (+/- {cv_scores.std()*100:.2f}%)\")\n",
        "print(\"MODEL EVALUATION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt-VeRtxNK2Z"
      },
      "source": [
        "## Comprehensive Model Evaluation & Metrics Analysis\n",
        "\n",
        "This section provides a full evaluation of the trained classifier using a wide\n",
        "range of performance metrics, class-wise statistics, error diagnostics,\n",
        "confidence analysis, and generalization assessment.\n",
        "\n",
        "### 1. Overall Performance Metrics\n",
        "\n",
        "The following global metrics are computed to evaluate the model:\n",
        "\n",
        "- **Accuracy**\n",
        "- **Balanced Accuracy**\n",
        "- **Weighted Precision**\n",
        "- **Weighted Recall**\n",
        "- **Weighted F1-Score**\n",
        "- **Cohen’s Kappa**\n",
        "- **Matthews Correlation Coefficient (MCC)**\n",
        "- **Log Loss**\n",
        "\n",
        "These metrics reflect the model’s overall predictive strength and reliability.\n",
        "\n",
        "### 2. Per-Class Metrics\n",
        "\n",
        "Per-class evaluation includes:\n",
        "\n",
        "- **Support**\n",
        "- **Precision**\n",
        "- **Recall**\n",
        "- **F1-Score**\n",
        "\n",
        "This helps identify which Prakriti classes are well-predicted and which need improvement.\n",
        "\n",
        "### 3. Macro & Micro Averages\n",
        "\n",
        "To evaluate class imbalance:\n",
        "\n",
        "- **Macro Averages** (treat all classes equally)\n",
        "- **Micro Averages** (weighted by class frequency)\n",
        "\n",
        "These give additional insight into model behavior across unequal class distributions.\n",
        "\n",
        "### 4. Error Analysis\n",
        "\n",
        "We compute:\n",
        "\n",
        "- Overall **misclassification rate**\n",
        "- **Total misclassified samples**\n",
        "- **Class-wise error rates**\n",
        "\n",
        "This helps diagnose systematic weaknesses.\n",
        "\n",
        "### 5. Training vs Testing Error\n",
        "\n",
        "To check for overfitting or underfitting:\n",
        "\n",
        "- **Training Error**\n",
        "- **Testing Error**\n",
        "- **Generalization Gap**\n",
        "\n",
        "A large gap indicates overfitting.\n",
        "\n",
        "### 6. Model Confidence Analysis\n",
        "\n",
        "Using predicted probabilities, we examine:\n",
        "\n",
        "- Mean, Min, Max & Standard Deviation of prediction confidence\n",
        "- Confidence of **correct** vs **incorrect** predictions\n",
        "\n",
        "This reveals whether the model is confidently wrong or uncertain.\n",
        "\n",
        "### 7. Saving Metrics\n",
        "\n",
        "All metrics are stored in a serialized `.pkl` file for future visualization,\n",
        "reporting, or comparative evaluation.\n",
        "\n",
        "This comprehensive analysis ensures full visibility into model behavior across\n",
        "accuracy, robustness, class balance, generalization, and decision confidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wPduEDjpNK2a",
        "outputId": "d46f3956-d8b1-42be-cd4a-9c71fb286385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPREHENSIVE METRICS ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "OVERALL PERFORMANCE METRICS\n",
            "================================================================================\n",
            "Accuracy: 95.8904%\n",
            "Balanced Accuracy: 98.2143%\n",
            "Precision (Weighted): 96.5101%\n",
            "Recall (Weighted): 95.8904%\n",
            "F1-Score (Weighted): 96.0015%\n",
            "Cohen's Kappa: 0.8988\n",
            "Matthews Correlation Coefficient: 0.9034\n",
            "Log Loss: 0.1905\n",
            "\n",
            "================================================================================\n",
            "PER-CLASS METRICS\n",
            "================================================================================\n",
            "Class  Support  Precision   Recall  F1-Score\n",
            "Kapha       12   0.857143 1.000000  0.923077\n",
            "Pitta       56   1.000000 0.946429  0.972477\n",
            " Vata        5   0.833333 1.000000  0.909091\n",
            "\n",
            "================================================================================\n",
            "AVERAGING METHODS\n",
            "================================================================================\n",
            "Macro Avg Precision: 89.6825%\n",
            "Macro Avg Recall: 98.2143%\n",
            "Macro Avg F1: 93.4882%\n",
            "Micro Avg Precision: 95.8904%\n",
            "Micro Avg Recall: 95.8904%\n",
            "Micro Avg F1: 95.8904%\n",
            "\n",
            "================================================================================\n",
            "ERROR ANALYSIS\n",
            "================================================================================\n",
            "Misclassification Rate: 4.1096%\n",
            "Total Misclassifications: 3\n",
            "\n",
            "Class-wise Errors:\n",
            "  Kapha: 0/12 misclassified (0.00%)\n",
            "  Pitta: 3/56 misclassified (5.36%)\n",
            "  Vata: 0/5 misclassified (0.00%)\n",
            "\n",
            "================================================================================\n",
            "TRAINING VS TESTING ERROR\n",
            "================================================================================\n",
            "Training Error: 0.3425%\n",
            "Testing Error: 4.1096%\n",
            "Generalization Gap: 3.7671%\n",
            "\n",
            "================================================================================\n",
            "MODEL CONFIDENCE ANALYSIS\n",
            "================================================================================\n",
            "Avg Confidence (Correct Predictions): 86.10%\n",
            "Avg Confidence (Incorrect Predictions): 52.67%\n",
            "\n",
            "================================================================================\n",
            "METRICS ANALYSIS COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Comprehensive metrics saved at: /content/Comprehensive_Metrics.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, cohen_kappa_score, matthews_corrcoef, log_loss,\n",
        "    precision_score, recall_score, f1_score,\n",
        "    precision_recall_fscore_support, balanced_accuracy_score\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE METRICS ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# Use the trained model instance\n",
        "# --------------------------------------------------------\n",
        "model = rf  # <-- trained RandomForestClassifier instance\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# OVERALL METRICS\n",
        "# --------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"OVERALL PERFORMANCE METRICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {test_accuracy*100:.4f}%\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)*100:.4f}%\")\n",
        "print(f\"Precision (Weighted): {precision*100:.4f}%\")\n",
        "print(f\"Recall (Weighted): {recall*100:.4f}%\")\n",
        "print(f\"F1-Score (Weighted): {f1*100:.4f}%\")\n",
        "\n",
        "# Cohen's Kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "\n",
        "# Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "\n",
        "# Log Loss\n",
        "y_pred_proba = model.predict_proba(X_test)\n",
        "logloss = log_loss(y_test, y_pred_proba)\n",
        "print(f\"Log Loss: {logloss:.4f}\")\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# PER-CLASS METRICS\n",
        "# --------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PER-CLASS METRICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "classes = sorted(y_test.unique())\n",
        "precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
        "    y_test, y_pred, labels=classes, zero_division=0\n",
        ")\n",
        "\n",
        "class_metrics = pd.DataFrame({\n",
        "    'Class': classes,\n",
        "    'Support': support_per_class,\n",
        "    'Precision': precision_per_class,\n",
        "    'Recall': recall_per_class,\n",
        "    'F1-Score': f1_per_class\n",
        "})\n",
        "\n",
        "print(class_metrics.to_string(index=False))\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# MACRO & MICRO AVERAGES\n",
        "# --------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"AVERAGING METHODS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "\n",
        "print(f\"Macro Avg Precision: {precision_macro*100:.4f}%\")\n",
        "print(f\"Macro Avg Recall: {recall_macro*100:.4f}%\")\n",
        "print(f\"Macro Avg F1: {f1_macro*100:.4f}%\")\n",
        "print(f\"Micro Avg Precision: {precision_micro*100:.4f}%\")\n",
        "print(f\"Micro Avg Recall: {recall_micro*100:.4f}%\")\n",
        "print(f\"Micro Avg F1: {f1_micro*100:.4f}%\")\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# ERROR ANALYSIS\n",
        "# --------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "misclassification_rate = 1 - test_accuracy\n",
        "total_errors = (y_test != y_pred).sum()\n",
        "print(f\"Misclassification Rate: {misclassification_rate*100:.4f}%\")\n",
        "print(f\"Total Misclassifications: {total_errors}\")\n",
        "\n",
        "print(\"\\nClass-wise Errors:\")\n",
        "for cls in classes:\n",
        "    mask = y_test == cls\n",
        "    errors = (y_test[mask] != y_pred[mask]).sum()\n",
        "    total = mask.sum()\n",
        "    error_rate = (errors / total * 100) if total > 0 else 0\n",
        "    print(f\"  {cls}: {errors}/{total} misclassified ({error_rate:.2f}%)\")\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# TRAINING VS TESTING\n",
        "# --------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING VS TESTING ERROR\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_error = 1 - train_acc\n",
        "test_error = 1 - test_accuracy\n",
        "\n",
        "print(f\"Training Error: {train_error*100:.4f}%\")\n",
        "print(f\"Testing Error: {test_error*100:.4f}%\")\n",
        "print(f\"Generalization Gap: {(test_error - train_error)*100:.4f}%\")\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# CONFIDENCE ANALYSIS\n",
        "# --------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL CONFIDENCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "prediction_confidence = y_pred_proba.max(axis=1)\n",
        "correct_mask = (y_test == y_pred)\n",
        "\n",
        "correct_conf = prediction_confidence[correct_mask].mean()\n",
        "incorrect_conf = prediction_confidence[~correct_mask].mean()\n",
        "\n",
        "print(f\"Avg Confidence (Correct Predictions): {correct_conf*100:.2f}%\")\n",
        "print(f\"Avg Confidence (Incorrect Predictions): {incorrect_conf*100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"METRICS ANALYSIS COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# SAVE METRICS\n",
        "# --------------------------------------------------------\n",
        "metrics_summary = {\n",
        "    'Overall Metrics': {\n",
        "        'Accuracy': test_accuracy,\n",
        "        'Balanced Accuracy': balanced_accuracy_score(y_test, y_pred),\n",
        "        'Precision (Weighted)': precision,\n",
        "        'Recall (Weighted)': recall,\n",
        "        'F1-Score (Weighted)': f1,\n",
        "        'Cohen Kappa': kappa,\n",
        "        'Matthews Correlation': mcc,\n",
        "        'Log Loss': logloss\n",
        "    },\n",
        "    'Per-Class Metrics': class_metrics.to_dict(),\n",
        "    'Macro Averages': {\n",
        "        'Precision': precision_macro,\n",
        "        'Recall': recall_macro,\n",
        "        'F1-Score': f1_macro\n",
        "    },\n",
        "    'Micro Averages': {\n",
        "        'Precision': precision_micro,\n",
        "        'Recall': recall_micro,\n",
        "        'F1-Score': f1_micro\n",
        "    },\n",
        "    'Error Analysis': {\n",
        "        'Misclassification Rate': misclassification_rate,\n",
        "        'Total Errors': int(total_errors),\n",
        "        'Training Error': train_error,\n",
        "        'Testing Error': test_error,\n",
        "        'Generalization Gap': test_error - train_error\n",
        "    },\n",
        "    'Confidence Analysis': {\n",
        "        'Mean Confidence': prediction_confidence.mean(),\n",
        "        'Min Confidence': prediction_confidence.min(),\n",
        "        'Max Confidence': prediction_confidence.max(),\n",
        "        'Std Confidence': prediction_confidence.std(),\n",
        "        'Correct Predictions Confidence': correct_conf,\n",
        "        'Incorrect Predictions Confidence': incorrect_conf\n",
        "    }\n",
        "}\n",
        "\n",
        "metrics_file = os.path.join(base_path, \"Comprehensive_Metrics.pkl\")\n",
        "with open(metrics_file, \"wb\") as f:\n",
        "    pickle.dump(metrics_summary, f)\n",
        "\n",
        "print(f\"\\nComprehensive metrics saved at: {metrics_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all objects in globals() that have predict_proba method\n",
        "for var_name, obj in globals().items():\n",
        "    try:\n",
        "        if hasattr(obj, \"predict\") and hasattr(obj, \"predict_proba\"):\n",
        "            print(f\"Trained model found: {var_name}\")\n",
        "    except:\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MTYRzpHKTXYS",
        "outputId": "508c3c94-7beb-425d-e356-5f4db9e4e3b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model found: RandomForestClassifier\n",
            "Trained model found: rf\n",
            "Trained model found: model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro24oY-4NK2a"
      },
      "source": [
        "## Comprehensive Metrics Analysis\n",
        "\n",
        "This section evaluates the overall performance of the trained model using\n",
        "multiple evaluation metrics.  \n",
        "It includes:\n",
        "\n",
        "- Overall accuracy-based metrics  \n",
        "- Per-class precision, recall, F1  \n",
        "- Macro & micro averaged performance  \n",
        "- Error and misclassification analysis  \n",
        "- Training vs testing performance gap  \n",
        "- Model confidence distribution  \n",
        "- Export of all computed metrics to a serialized file (`pickle`)\n",
        "\n",
        "\n",
        "### **Sections Included**\n",
        "\n",
        "#### **1. Overall Performance Metrics**\n",
        "Measures the global performance of the classifier:\n",
        "- Accuracy  \n",
        "- Balanced Accuracy  \n",
        "- Weighted Precision, Recall, F1  \n",
        "- Cohen’s Kappa  \n",
        "- Matthews Correlation Coefficient (MCC)  \n",
        "- Log Loss  \n",
        "\n",
        "\n",
        "#### **2. Per-Class Metrics**\n",
        "This includes class-wise:\n",
        "- Support  \n",
        "- Precision  \n",
        "- Recall  \n",
        "- F1-Score  \n",
        "\n",
        "Useful for detecting class imbalance or systematic class errors.\n",
        "\n",
        "\n",
        "#### **3. Averaging Methods**\n",
        "Provides:\n",
        "- Macro-Averaged Precision, Recall, F1  \n",
        "- Micro-Averaged Precision, Recall, F1  \n",
        "\n",
        "These help understand performance from a dataset-level perspective.\n",
        "\n",
        "\n",
        "#### **4. Error Analysis**\n",
        "Includes:\n",
        "- Misclassification rate  \n",
        "- Total incorrect predictions  \n",
        "- Class-wise error breakdown  \n",
        "\n",
        "\n",
        "#### **5. Training vs Testing Error**\n",
        "Helps identify:\n",
        "- Underfitting  \n",
        "- Overfitting  \n",
        "- Generalization gap  \n",
        "\n",
        "\n",
        "#### **6. Model Confidence Analysis**\n",
        "Analyzes:\n",
        "- Average confidence of predictions  \n",
        "- Min/Max confidence  \n",
        "- Standard deviation of confidence  \n",
        "- Confidence for correct vs incorrect predictions  \n",
        "\n",
        "\n",
        "#### **7. Exporting Metric Summary**\n",
        "All results are stored in a `.pkl` file so they can be loaded later for evaluation or reporting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "G1LKxi8gNK2a",
        "outputId": "28c91341-e088-45ac-82d0-8cc2a0744993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPREHENSIVE METRICS ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "OVERALL PERFORMANCE METRICS\n",
            "================================================================================\n",
            "Accuracy: 95.8904%\n",
            "Balanced Accuracy: 98.2143%\n",
            "Precision (Weighted): 96.5101%\n",
            "Recall (Weighted): 95.8904%\n",
            "F1-Score (Weighted): 96.0015%\n",
            "Cohen's Kappa: 0.8988\n",
            "Matthews Correlation Coefficient: 0.9034\n",
            "Log Loss: 0.1905\n",
            "\n",
            "================================================================================\n",
            "PER-CLASS METRICS\n",
            "================================================================================\n",
            "Class  Support  Precision   Recall  F1-Score\n",
            "Kapha       12   0.857143 1.000000  0.923077\n",
            "Pitta       56   1.000000 0.946429  0.972477\n",
            " Vata        5   0.833333 1.000000  0.909091\n",
            "\n",
            "================================================================================\n",
            "AVERAGING METHODS\n",
            "================================================================================\n",
            "Macro Average Precision: 89.6825%\n",
            "Macro Average Recall: 98.2143%\n",
            "Macro Average F1-Score: 93.4882%\n",
            "\n",
            "Micro Average Precision: 95.8904%\n",
            "Micro Average Recall: 95.8904%\n",
            "Micro Average F1-Score: 95.8904%\n",
            "\n",
            "================================================================================\n",
            "ERROR ANALYSIS\n",
            "================================================================================\n",
            "Misclassification Rate: 4.1096%\n",
            "Total Misclassifications: 3 out of 73\n",
            "\n",
            "Class-wise Errors:\n",
            "  Kapha: 0/12 misclassified (0.00% error rate)\n",
            "  Pitta: 3/56 misclassified (5.36% error rate)\n",
            "  Vata: 0/5 misclassified (0.00% error rate)\n",
            "\n",
            "================================================================================\n",
            "TRAINING VS TESTING ERROR\n",
            "================================================================================\n",
            "Training Error: 0.3425%\n",
            "Testing Error: 4.1096%\n",
            "Generalization Gap: 3.7671%\n",
            "\n",
            "================================================================================\n",
            "MODEL CONFIDENCE ANALYSIS\n",
            "================================================================================\n",
            "Average Confidence: 84.73%\n",
            "Min Confidence: 48.33%\n",
            "Max Confidence: 99.58%\n",
            "Std Confidence: 14.14%\n",
            "Average Confidence (Correct Predictions): 86.10%\n",
            "Average Confidence (Incorrect Predictions): 52.67%\n",
            "\n",
            "================================================================================\n",
            "METRICS ANALYSIS COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Comprehensive metrics saved: /content\\Comprehensive_Metrics.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.metrics import (cohen_kappa_score, matthews_corrcoef, log_loss,\n",
        "                             precision_score, recall_score, f1_score,\n",
        "                             precision_recall_fscore_support, balanced_accuracy_score)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE METRICS ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Overall Metrics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"OVERALL PERFORMANCE METRICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {test_accuracy*100:.4f}%\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)*100:.4f}%\")\n",
        "print(f\"Precision (Weighted): {precision*100:.4f}%\")\n",
        "print(f\"Recall (Weighted): {recall*100:.4f}%\")\n",
        "print(f\"F1-Score (Weighted): {f1*100:.4f}%\")\n",
        "\n",
        "# Cohen's Kappa\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
        "\n",
        "# Matthews Correlation Coefficient\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "\n",
        "# Log Loss (requires probability predictions)\n",
        "rf_model = model\n",
        "y_pred_proba = rf_model.predict_proba(X_test)\n",
        "logloss = log_loss(y_test, y_pred_proba)\n",
        "print(f\"Log Loss: {logloss:.4f}\")\n",
        "\n",
        "# Per-Class Metrics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PER-CLASS METRICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "classes = sorted(y_test.unique())\n",
        "precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(\n",
        "    y_test, y_pred, labels=classes, zero_division=0\n",
        ")\n",
        "\n",
        "class_metrics = pd.DataFrame({\n",
        "    'Class': classes,\n",
        "    'Support': support_per_class,\n",
        "    'Precision': precision_per_class,\n",
        "    'Recall': recall_per_class,\n",
        "    'F1-Score': f1_per_class\n",
        "})\n",
        "print(class_metrics.to_string(index=False))\n",
        "\n",
        "# Macro and Micro averages\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"AVERAGING METHODS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "print(f\"Macro Average Precision: {precision_macro*100:.4f}%\")\n",
        "print(f\"Macro Average Recall: {recall_macro*100:.4f}%\")\n",
        "print(f\"Macro Average F1-Score: {f1_macro*100:.4f}%\")\n",
        "\n",
        "precision_micro = precision_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "recall_micro = recall_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "print(f\"\\nMicro Average Precision: {precision_micro*100:.4f}%\")\n",
        "print(f\"Micro Average Recall: {recall_micro*100:.4f}%\")\n",
        "print(f\"Micro Average F1-Score: {f1_micro*100:.4f}%\")\n",
        "\n",
        "# Error Analysis\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "misclassification_rate = 1 - test_accuracy\n",
        "total_errors = (y_test != y_pred).sum()\n",
        "print(f\"Misclassification Rate: {misclassification_rate*100:.4f}%\")\n",
        "print(f\"Total Misclassifications: {total_errors} out of {len(y_test)}\")\n",
        "\n",
        "print(\"\\nClass-wise Errors:\")\n",
        "for cls in classes:\n",
        "    mask = y_test == cls\n",
        "    errors = (y_test[mask] != y_pred[mask]).sum()\n",
        "    total = mask.sum()\n",
        "    error_rate = errors / total * 100 if total > 0 else 0\n",
        "    print(f\"  {cls}: {errors}/{total} misclassified ({error_rate:.2f}% error rate)\")\n",
        "\n",
        "# Training vs Testing Error\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING VS TESTING ERROR\")\n",
        "print(\"=\"*80)\n",
        "train_error = 1 - train_acc\n",
        "test_error = 1 - test_accuracy\n",
        "print(f\"Training Error: {train_error*100:.4f}%\")\n",
        "print(f\"Testing Error: {test_error*100:.4f}%\")\n",
        "print(f\"Generalization Gap: {(test_error - train_error)*100:.4f}%\")\n",
        "\n",
        "# Model Confidence Analysis\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL CONFIDENCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "prediction_confidence = y_pred_proba.max(axis=1)\n",
        "print(f\"Average Confidence: {prediction_confidence.mean()*100:.2f}%\")\n",
        "print(f\"Min Confidence: {prediction_confidence.min()*100:.2f}%\")\n",
        "print(f\"Max Confidence: {prediction_confidence.max()*100:.2f}%\")\n",
        "print(f\"Std Confidence: {prediction_confidence.std()*100:.2f}%\")\n",
        "\n",
        "correct_mask = y_test == y_pred\n",
        "correct_confidence = prediction_confidence[correct_mask].mean() if correct_mask.sum() > 0 else 0\n",
        "incorrect_confidence = prediction_confidence[~correct_mask].mean() if (~correct_mask).sum() > 0 else 0\n",
        "print(f\"Average Confidence (Correct Predictions): {correct_confidence*100:.2f}%\")\n",
        "print(f\"Average Confidence (Incorrect Predictions): {incorrect_confidence*100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"METRICS ANALYSIS COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save comprehensive metrics to file\n",
        "metrics_summary = {\n",
        "    'Overall Metrics': {\n",
        "        'Accuracy': test_accuracy,\n",
        "        'Balanced Accuracy': balanced_accuracy_score(y_test, y_pred),\n",
        "        'Precision (Weighted)': precision,\n",
        "        'Recall (Weighted)': recall,\n",
        "        'F1-Score (Weighted)': f1,\n",
        "        'Cohen Kappa': kappa,\n",
        "        'Matthews Correlation': mcc,\n",
        "        'Log Loss': logloss\n",
        "    },\n",
        "    'Per-Class Metrics': class_metrics.to_dict(),\n",
        "    'Macro Averages': {\n",
        "        'Precision': precision_macro,\n",
        "        'Recall': recall_macro,\n",
        "        'F1-Score': f1_macro\n",
        "    },\n",
        "    'Micro Averages': {\n",
        "        'Precision': precision_micro,\n",
        "        'Recall': recall_micro,\n",
        "        'F1-Score': f1_micro\n",
        "    },\n",
        "    'Error Analysis': {\n",
        "        'Misclassification Rate': misclassification_rate,\n",
        "        'Total Errors': int(total_errors),\n",
        "        'Training Error': train_error,\n",
        "        'Testing Error': test_error,\n",
        "        'Generalization Gap': test_error - train_error\n",
        "    },\n",
        "    'Confidence Analysis': {\n",
        "        'Mean Confidence': prediction_confidence.mean(),\n",
        "        'Min Confidence': prediction_confidence.min(),\n",
        "        'Max Confidence': prediction_confidence.max(),\n",
        "        'Std Confidence': prediction_confidence.std(),\n",
        "        'Correct Predictions Confidence': correct_confidence,\n",
        "        'Incorrect Predictions Confidence': incorrect_confidence\n",
        "    }\n",
        "}\n",
        "\n",
        "metrics_file = f\"{base_path}\\\\Comprehensive_Metrics.pkl\"\n",
        "with open(metrics_file, 'wb') as f:\n",
        "    pickle.dump(metrics_summary, f)\n",
        "print(f\"\\nComprehensive metrics saved: {metrics_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJBeNOR7NK2a"
      },
      "source": [
        "## Comprehensive Model Evaluation & Metrics Analysis\n",
        "\n",
        "This section presents an extensive evaluation of the trained model using a diverse\n",
        "set of performance metrics, class-wise insights, error analysis, and confidence\n",
        "estimation. The purpose of this block is to provide a complete understanding of how\n",
        "the model behaves both globally and on a per-class basis.\n",
        "\n",
        "### **1. Overall Performance Metrics**\n",
        "\n",
        "We compute commonly used classification metrics including:\n",
        "\n",
        "- **Accuracy**\n",
        "- **Balanced Accuracy**\n",
        "- **Weighted Precision**\n",
        "- **Weighted Recall**\n",
        "- **Weighted F1-Score**\n",
        "- **Cohen’s Kappa**\n",
        "- **Matthews Correlation Coefficient (MCC)**\n",
        "- **Log Loss (using probability predictions)**\n",
        "\n",
        "These metrics collectively describe the model’s general predictive performance.\n",
        "\n",
        "\n",
        "### **2. Per-Class Metrics**\n",
        "\n",
        "For each class (Prakriti category), the following are evaluated:\n",
        "\n",
        "- **Support**  \n",
        "- **Precision**\n",
        "- **Recall**\n",
        "- **F1-Score**\n",
        "\n",
        "This helps identify which dosha types the model predicts reliably and where it struggles.\n",
        "\n",
        "\n",
        "### **3. Macro & Micro Average Metrics**\n",
        "\n",
        "We calculate:\n",
        "\n",
        "- **Macro Averages**: Treat all classes equally  \n",
        "- **Micro Averages**: Weighted by sample count  \n",
        "\n",
        "These give additional perspective on class imbalance effects.\n",
        "\n",
        "\n",
        "### **4. Error Analysis**\n",
        "\n",
        "This includes:\n",
        "\n",
        "- Overall **misclassification rate**\n",
        "- **Total number of misclassified samples**\n",
        "- **Class-wise error rates**\n",
        "\n",
        "This aids in diagnosing model weaknesses or problematic classes.\n",
        "\n",
        "\n",
        "### **5. Training vs Testing Error**\n",
        "\n",
        "To check for underfitting or overfitting, we compute:\n",
        "\n",
        "- Training Error  \n",
        "- Testing Error  \n",
        "- **Generalization Gap**\n",
        "\n",
        "A large gap indicates overfitting.\n",
        "\n",
        "\n",
        "### **6. Model Confidence Analysis**\n",
        "\n",
        "We examine predicted probability distributions to compute:\n",
        "\n",
        "- Mean, Min, Max, Standard Deviation of prediction confidence  \n",
        "- Confidence for **correct** vs **incorrect** predictions  \n",
        "\n",
        "This reveals whether the model is confidently wrong or uncertain overall.\n",
        "\n",
        "\n",
        "### **7. Saving Metrics**\n",
        "\n",
        "All metrics and detailed analysis results are stored in a `.pkl` file for future\n",
        "reference or further visualization.\n",
        "\n",
        "This comprehensive evaluation ensures that every aspect of the model’s behavior—\n",
        "accuracy, robustness, reliability, and error characteristics—is thoroughly captured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K7RnC8zxNK2b",
        "outputId": "bd8e2144-55db-4f87-cefa-7a5fbad9e1f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RANDOM FOREST REPORT ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Kapha       0.86      1.00      0.92        12\n",
            "       Pitta       1.00      0.95      0.97        56\n",
            "        Vata       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.96        73\n",
            "   macro avg       0.90      0.98      0.93        73\n",
            "weighted avg       0.97      0.96      0.96        73\n",
            "\n",
            "\n",
            "=== MLP REPORT ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Kapha       0.70      0.58      0.64        12\n",
            "       Pitta       0.88      0.95      0.91        56\n",
            "        Vata       0.67      0.40      0.50         5\n",
            "\n",
            "    accuracy                           0.85        73\n",
            "   macro avg       0.75      0.64      0.68        73\n",
            "weighted avg       0.84      0.85      0.84        73\n",
            "\n",
            "\n",
            "=== RANDOM FOREST vs MLP COMPARISON ===\n",
            "           Metric Random Forest    MLP\n",
            "Training Accuracy        99.66% 97.26%\n",
            " Testing Accuracy        95.89% 84.93%\n",
            "        Precision        96.51% 83.84%\n",
            "           Recall        95.89% 84.93%\n",
            "         F1-Score        96.00% 83.98%\n",
            "      CV Accuracy        94.79% 78.76%\n",
            "\n",
            "Top 10 Features by Random Forest Importance:\n",
            "             Feature  Importance\n",
            "     Vata_Score_mean    0.058913\n",
            "    Pitta_Score_mean    0.051419\n",
            " Vata_Percentage_max    0.050739\n",
            " Vata_Percentage_min    0.045769\n",
            "     Kapha_Score_min    0.045733\n",
            "      Vata_Score_min    0.045328\n",
            "Pitta_Percentage_max    0.042304\n",
            "Pitta_Percentage_min    0.041967\n",
            "     Pitta_Score_min    0.041238\n",
            "      Vata_Score_max    0.040233\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GroupKFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             classification_report, confusion_matrix, precision_recall_fscore_support,\n",
        "                             balanced_accuracy_score, cohen_kappa_score, matthews_corrcoef, log_loss)\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = \"Dataset.csv\"\n",
        "df = pd.read_csv(dataset_path, encoding='utf-8-sig')\n",
        "\n",
        "# Keep only numeric columns for aggregation\n",
        "numeric_features = df.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_features = [f for f in numeric_features if f not in ['Student_ID']]\n",
        "\n",
        "# Aggregate numeric features per student\n",
        "df_agg = df.groupby('SRN')[numeric_features].agg(['mean','std','min','max'])\n",
        "df_agg.columns = ['_'.join(col).strip() for col in df_agg.columns.values]\n",
        "df_agg = df_agg.reset_index()\n",
        "\n",
        "# Merge labels\n",
        "labels = df[['SRN','Dominant_Prakriti']].drop_duplicates()\n",
        "df_final = pd.merge(df_agg, labels, on='SRN', how='left')\n",
        "\n",
        "# Features & target\n",
        "X = df_final.drop(columns=['SRN','Dominant_Prakriti'])\n",
        "y = df_final['Dominant_Prakriti']\n",
        "groups = df_final['SRN']\n",
        "\n",
        "# Student-level train-test split\n",
        "unique_srns = df_final['SRN'].unique()\n",
        "train_srns, test_srns = train_test_split(unique_srns, test_size=0.2, random_state=42)\n",
        "X_train = X[df_final['SRN'].isin(train_srns)]\n",
        "y_train = y[df_final['SRN'].isin(train_srns)]\n",
        "X_test = X[df_final['SRN'].isin(test_srns)]\n",
        "y_test = y[df_final['SRN'].isin(test_srns)]\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# RANDOM FOREST MODEL\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_test_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "train_accuracy_rf = rf_model.score(X_train, y_train)\n",
        "test_accuracy_rf = accuracy_score(y_test, y_pred_test_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_test_rf, average='weighted', zero_division=0)\n",
        "recall_rf = recall_score(y_test, y_pred_test_rf, average='weighted', zero_division=0)\n",
        "f1_rf = f1_score(y_test, y_pred_test_rf, average='weighted', zero_division=0)\n",
        "\n",
        "\n",
        "# 5-Fold Cross-Validation\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "cv_scores_rf = cross_val_score(rf_model, X, y, groups=groups, cv=gkf)\n",
        "\n",
        "# MLP MODEL\n",
        "mlp_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('mlp', MLPClassifier(\n",
        "        hidden_layer_sizes=(128,64,32),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        early_stopping=True,\n",
        "        validation_fraction=0.1,\n",
        "        n_iter_no_change=20\n",
        "    ))\n",
        "])\n",
        "mlp_pipeline.fit(X_train, y_train_encoded)\n",
        "y_pred_test_mlp_encoded = mlp_pipeline.predict(X_test)\n",
        "y_pred_test_mlp = label_encoder.inverse_transform(y_pred_test_mlp_encoded)\n",
        "\n",
        "# Metrics MLP\n",
        "train_accuracy_mlp = accuracy_score(y_train, label_encoder.inverse_transform(mlp_pipeline.predict(X_train)))\n",
        "test_accuracy_mlp = accuracy_score(y_test, y_pred_test_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_test_mlp, average='weighted', zero_division=0)\n",
        "recall_mlp = recall_score(y_test, y_pred_test_mlp, average='weighted', zero_division=0)\n",
        "f1_mlp = f1_score(y_test, y_pred_test_mlp, average='weighted', zero_division=0)\n",
        "cv_scores_mlp = cross_val_score(mlp_pipeline, X_train, y_train_encoded, cv=5)\n",
        "\n",
        "# Confusion matrices\n",
        "cm_rf = confusion_matrix(y_test, y_pred_test_rf)\n",
        "cm_mlp = confusion_matrix(y_test, y_pred_test_mlp)\n",
        "\n",
        "# Classification reports\n",
        "print(\"\\n=== RANDOM FOREST REPORT ===\")\n",
        "print(classification_report(y_test, y_pred_test_rf, zero_division=0))\n",
        "print(\"\\n=== MLP REPORT ===\")\n",
        "print(classification_report(y_test, y_pred_test_mlp, zero_division=0))\n",
        "\n",
        "# Comparison\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Training Accuracy', 'Testing Accuracy', 'Precision', 'Recall', 'F1-Score', 'CV Accuracy'],\n",
        "    'Random Forest': [\n",
        "        f\"{train_accuracy_rf*100:.2f}%\",\n",
        "        f\"{test_accuracy_rf*100:.2f}%\",\n",
        "        f\"{precision_rf*100:.2f}%\",\n",
        "        f\"{recall_rf*100:.2f}%\",\n",
        "        f\"{f1_rf*100:.2f}%\",\n",
        "        f\"{cv_scores_rf.mean()*100:.2f}%\"\n",
        "    ],\n",
        "    'MLP': [\n",
        "        f\"{train_accuracy_mlp*100:.2f}%\",\n",
        "        f\"{test_accuracy_mlp*100:.2f}%\",\n",
        "        f\"{precision_mlp*100:.2f}%\",\n",
        "        f\"{recall_mlp*100:.2f}%\",\n",
        "        f\"{f1_mlp*100:.2f}%\",\n",
        "        f\"{cv_scores_mlp.mean()*100:.2f}%\"\n",
        "    ]\n",
        "})\n",
        "print(\"\\n=== RANDOM FOREST vs MLP COMPARISON ===\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Feature importance (RF)\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Features by Random Forest Importance:\")\n",
        "print(feature_importance_df.head(10).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-20T16:14:31.890337Z",
          "iopub.status.busy": "2025-11-20T16:14:31.889942Z",
          "iopub.status.idle": "2025-11-20T16:14:33.957123Z",
          "shell.execute_reply": "2025-11-20T16:14:33.955819Z",
          "shell.execute_reply.started": "2025-11-20T16:14:31.890312Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "OjMRcWIANK2b",
        "outputId": "a5b693e3-92dc-4ed0-dab9-af5752d74e11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Features by Importance:\n",
            "              Feature  Importance\n",
            "94        Vata_Score    0.145445\n",
            "97   Vata_Percentage    0.142008\n",
            "99  Kapha_Percentage    0.127116\n",
            "98  Pitta_Percentage    0.125051\n",
            "95       Pitta_Score    0.105986\n",
            "96       Kapha_Score    0.105622\n",
            "42                43    0.008926\n",
            "36                37    0.008581\n",
            "59                60    0.005992\n",
            "38                39    0.005828\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ==============================\n",
        "# Select numeric features from original dataset (exclude IDs and labels)\n",
        "# ==============================\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_cols = [col for col in numeric_cols if col not in ['SRN', 'Student_ID']]\n",
        "\n",
        "X_orig = df[numeric_cols]\n",
        "y_orig = df['Dominant_Prakriti']\n",
        "\n",
        "# ==============================\n",
        "# Train Random Forest on original data\n",
        "# ==============================\n",
        "rf_orig = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "rf_orig.fit(X_orig, y_orig)\n",
        "\n",
        "# ==============================\n",
        "# Feature Importances\n",
        "# ==============================\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_orig.columns,\n",
        "    'Importance': rf_orig.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "top_features = feature_importance_df.head(10)\n",
        "\n",
        "# ==============================\n",
        "# Plot Top 10 Features\n",
        "# ==============================\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')\n",
        "plt.title('Top 10 Important Features (Original Dataset)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: print top 10 features\n",
        "print(\"\\nTop 10 Features by Importance:\\n\", top_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oXk96e09NK2b",
        "outputId": "77a412ee-1dc0-4446-96d6-f75d83a83a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.7650, Val Loss: 0.5128\n",
            "Epoch [10/100], Loss: 0.0112, Val Loss: 1.3071\n",
            "Early stopping at epoch 11\n",
            "\n",
            "=============================\n",
            "FFN MODEL PERFORMANCE\n",
            "=============================\n",
            "Training Accuracy: 92.39%\n",
            "Testing Accuracy: 80.14%\n",
            "Precision: 84.37%\n",
            "Recall: 80.14%\n",
            "F1-Score: 81.20%\n",
            "\n",
            "Confusion Matrix:\n",
            "[[154  28   0]\n",
            " [ 88 597  71]\n",
            " [  2  14  68]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Kapha       0.63      0.85      0.72       182\n",
            "       Pitta       0.93      0.79      0.86       756\n",
            "        Vata       0.49      0.81      0.61        84\n",
            "\n",
            "    accuracy                           0.80      1022\n",
            "   macro avg       0.68      0.82      0.73      1022\n",
            "weighted avg       0.84      0.80      0.81      1022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# LOAD DATA\n",
        "dataset_path = \"Dataset.csv\"\n",
        "df = pd.read_csv(dataset_path, encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "# FEATURES & TARGET\n",
        "# Only numeric speech features\n",
        "speech_features = [col for col in df.columns if col not in ['SRN','Dominant_Prakriti','Student_ID','Name','AudioFileName']]\n",
        "X = df[speech_features]\n",
        "y = df['Dominant_Prakriti']\n",
        "\n",
        "unique_srns = df['SRN'].unique()\n",
        "train_srns, test_srns = train_test_split(unique_srns, test_size=0.2, random_state=42)\n",
        "X_train = X[df['SRN'].isin(train_srns)]\n",
        "y_train = y[df['SRN'].isin(train_srns)]\n",
        "X_test = X[df['SRN'].isin(test_srns)]\n",
        "y_test = y[df['SRN'].isin(test_srns)]\n",
        "\n",
        "\n",
        "# SCALE FEATURES\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# ENCODE TARGET\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "n_classes = len(label_encoder.classes_)\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "\n",
        "\n",
        "# CLASS WEIGHTS (HANDLE IMBALANCE)\n",
        "class_counts = np.bincount(y_train_encoded)\n",
        "class_weights = 1. / class_counts\n",
        "sample_weights = class_weights[y_train_encoded]\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# CONVERT TO TORCH TENSORS\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# DEFINE FFN MODEL\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims=[64,32], output_dim=n_classes):\n",
        "        super(FFN, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dims[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dims[1], output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "model = FFN(input_dim=input_dim)\n",
        "\n",
        "\n",
        "# LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "# TRAINING LOOP WITH EARLY STOPPING\n",
        "num_epochs = 100\n",
        "best_val_loss = np.inf\n",
        "patience = 10\n",
        "trigger_times = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation on test set for early stopping\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_test_tensor)\n",
        "        val_loss = criterion(val_outputs, y_test_tensor).item()\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), \"best_ffn_model.pth\")\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    if (epoch+1) % 10 == 0 or epoch==0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(\"best_ffn_model.pth\"))\n",
        "\n",
        "\n",
        "# EVALUATION\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_train_pred = model(X_train_tensor).argmax(dim=1).numpy()\n",
        "    y_test_pred = model(X_test_tensor).argmax(dim=1).numpy()\n",
        "\n",
        "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
        "precision = precision_score(y_test_encoded, y_test_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test_encoded, y_test_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test_encoded, y_test_pred, average='weighted', zero_division=0)\n",
        "\n",
        "print(\"\\n=============================\")\n",
        "print(\"FFN MODEL PERFORMANCE\")\n",
        "print(\"=============================\")\n",
        "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Testing Accuracy: {test_accuracy*100:.2f}%\")\n",
        "print(f\"Precision: {precision*100:.2f}%\")\n",
        "print(f\"Recall: {recall*100:.2f}%\")\n",
        "print(f\"F1-Score: {f1*100:.2f}%\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_encoded, y_test_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_encoded, y_test_pred, target_names=label_encoder.classes_, zero_division=0))"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 8790999,
          "sourceId": 13806210,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31192,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}